#!/bin/bash --login

########## Define Resources Needed with SBATCH Lines ##########
#SBATCH --job-name=BLASTN # give your job a name for easier identification (same as -J)
#SBATCH --time=168:00:00 # limit of wall clock time - how long will the job take to run? (same as -t)
#SBATCH --ntasks=1     # number of tasks - how many tasks (nodes) does your job require? (same as -n)
#SBATCH --cpus-per-task=9 # number of CPUs (or cores) per task (same as -c)
#SBATCH --mem=50G     # memory required per node - amount of memory (in bytes)
#SBATCH --output=/mnt/scratch/vascokar/marine_iguana/eofiles/blastN.%j.out #Standard output
#SBATCH --error=/mnt/scratch/vascokar/marine_iguana/eofiles/blastN.%j.err #Standard error log

########## Diplay the job context ######
echo Job: $SLUM_JOB_NAME with ID $SLURM_JOB_ID
echo Running on host `hostname`
echo Job started at `date '+%T %a %d %b %Y'`
echo Directory is `pwd`
echo Using $SLURM_NTASKS processors across $SLURM_NNODES nodes

######### Assign path variables ########
INPUT_DIRECTORY=/mnt/scratch/vascokar/marine_iguana/ACC_deeparg/fasta
OUTPUT_DIRECTORY=/mnt/scratch/vascokar/marine_iguana/ACC_deeparg/blastn

########## Modules to Load ##########
module purge
module load GCC/9.3.0  OpenMPI/4.0.3
module load BLAST+/2.10.1
export BLASTDB=/mnt/research/common-data/Bio/blastdb:/mnt/research/common-data/Bio/blastdb/v5:$BLASTDB

########## Code to Run ###########
cd $INPUT_DIRECTORY
for f in *.fasta # for each sample f
do
  n=${f%%.fasta} # strip part of file name

blastn \
 -query ${n}.fasta \
 -db nt \
 -out $OUTPUT_DIRECTORY/${n}_blastn.tsv \
 -evalue 0.001 \
 -num_threads 8 \
 -max_target_seqs 10 \
 -outfmt "6 qseqid qgi qlen sallseqid sallgi slen qstart qend sstart send evalue bitscore score length mismatch gapopen pident nident btop staxids sscinames scomnames sblastnames sskingdoms stitle qcovs qcovhsp"
done

##### Final time stamp ######
echo Job finished at `date '+%T %a %d %b %Y'`